{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63f5535-cfb9-4434-9921-8a1ecf84b440",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install segmentation-models-pytorch==0.3.3 pillow opencv-python matplotlib torch torchvision torchmetrics\n",
    "import torch, torch.nn as nn, cv2, numpy as np, matplotlib.pyplot as plt,  matplotlib\n",
    "from PIL import Image\n",
    "import segmentation_models_pytorch as smp\n",
    "from pathlib import Path, PurePosixPath\n",
    "matplotlib.rcParams[\"figure.dpi\"]=120\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eb3783-f28b-47f7-8b63-41d0f36e5b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_2010 = Image.open('orlando2010.png').convert('RGB')\n",
    "img_2023 = Image.open('orlando2023.png').convert('RGB')\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1); plt.title('2010'); plt.imshow(img_2010); plt.axis('off')\n",
    "plt.subplot(1,2,2); plt.title('2023'); plt.imshow(img_2023); plt.axis('off'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483ad7f7-2291-43d6-aa1a-8fcb38b53d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "class UNetBuildings(nn.Module):\n",
    "    def __init__(self, weights_url):\n",
    "        super().__init__()\n",
    "        self.net = smp.Unet(encoder_name=\"efficientnet-b0\", encoder_weights=None,\n",
    "                            classes=1, activation='sigmoid')\n",
    "        self.net.load_state_dict(torch.hub.load_state_dict_from_url(weights_url, map_location='cpu'))\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "b_weights = \"https://huggingface.co/FLAME/unet-eff-b0_buildings/resolve/main/pytorch_model.bin\"\n",
    "b_model   = UNetBuildings(b_weights).to(DEVICE).eval()\n",
    "\n",
    "def infer_mask(model, pil_img, thresh=0.35):\n",
    "    resize = (512,512)\n",
    "    img = pil_img.resize(resize)\n",
    "    arr = torch.tensor(np.array(img)/255.).permute(2,0,1).unsqueeze(0).float().to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        pred = model(arr)[0,0].cpu().numpy()\n",
    "    mask = (pred>thresh).astype(np.uint8)\n",
    "    mask = cv2.resize(mask, pil_img.size, interpolation=cv2.INTER_NEAREST)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dee586-dec5-427c-b26b-cc8474653bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "r_model = torchvision.models.segmentation.deeplabv3_resnet50(weights=\"DEFAULT\").to(DEVICE).eval()\n",
    "ROAD_LABELS = [0, 1, 2]  # Mapillary classes for road-like surfaces\n",
    "\n",
    "def infer_roads(pil_img, conf=0.50):\n",
    "    resize = (520,520)\n",
    "    img = pil_img.resize(resize)\n",
    "    tens = torchvision.transforms.functional.to_tensor(img).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad(): out = r_model(tens)['out'][0].softmax(0).cpu()\n",
    "    road_mask = np.zeros(out.shape[1:], dtype=np.uint8)\n",
    "    for lbl in ROAD_LABELS:\n",
    "        road_mask |= (out[lbl]>conf).numpy().astype(np.uint8)\n",
    "    road_mask = cv2.resize(road_mask, pil_img.size, interpolation=cv2.INTER_NEAREST)\n",
    "    return road_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28276605-4b55-47f9-ade8-c08e9c3a101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- run both detectors -----\n",
    "b10, b23 = infer_mask(b_model, img_2010), infer_mask(b_model, img_2023)\n",
    "r10, r23 = infer_roads(img_2010),        infer_roads(img_2023)\n",
    "\n",
    "# ----- new-infrastructure masks -----\n",
    "new_build = (b23 & ~b10).astype(np.uint8)\n",
    "new_road  = (r23 & ~r10).astype(np.uint8)\n",
    "\n",
    "# ----- overlay on 2023 image -----\n",
    "vis = np.array(img_2023).copy()\n",
    "vis[new_build==1] = [255,0,0]         # red buildings\n",
    "vis[new_road==1]  = [255,255,0]       # yellow roads\n",
    "\n",
    "plt.figure(figsize=(6,6)); plt.imshow(vis); plt.axis('off')\n",
    "plt.title('Neural Detection Overlay (2023)'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177af07a-9f4e-4908-bfbc-9f2017a04df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct(mask): return 100*mask.sum()/mask.size\n",
    "\n",
    "report = {\n",
    "    'building_2010_%': pct(b10),\n",
    "    'building_2023_%': pct(b23),\n",
    "    'road_2010_%':     pct(r10),\n",
    "    'road_2023_%':     pct(r23),\n",
    "}\n",
    "report['building_change_%'] = report['building_2023_%']-report['building_2010_%']\n",
    "report['road_change_%']     = report['road_2023_%']-report['road_2010_%']\n",
    "\n",
    "def text_report(d):\n",
    "    more_b = d['building_change_%']>0\n",
    "    more_r = d['road_change_%']>0\n",
    "    summary = (\"substantial expansion\" if d['building_change_%']>2 or d['road_change_%']>2 \n",
    "               else \"moderate changes\")\n",
    "    bullets = [\n",
    "      f\"Built-up footprint {'increased' if more_b else 'decreased'} by \"\n",
    "      f\"{abs(d['building_change_%']):.1f}% (from {d['building_2010_%']:.1f}% to {d['building_2023_%']:.1f}%).\",\n",
    "      f\"Paved road/taxiway coverage {'expanded' if more_r else 'reduced'} by \"\n",
    "      f\"{abs(d['road_change_%']):.1f}% (from {d['road_2010_%']:.1f}% to {d['road_2023_%']:.1f}%).\"\n",
    "    ]\n",
    "    return f\"\"\"\n",
    "ORLANDO AIRPORT – NEURAL NETWORK CHANGE REPORT\n",
    "Generated {datetime.date.today().isoformat()}\n",
    "\n",
    "Executive Summary\n",
    "-----------------\n",
    "Automated deep-learning segmentation reveals **{summary}** between 2010 and 2023.\n",
    "\n",
    "Key Findings\n",
    "------------\n",
    "• {bullets[0]}\n",
    "• {bullets[1]}\n",
    "\n",
    "Method\n",
    "------\n",
    "U-Net (EfficientNet-b0) for building footprints, DeepLabV3-R50 for roads/taxiways.\n",
    "Pixel-wise difference yields new-infrastructure masks visualised in overlay.\n",
    "\n",
    "Limitations\n",
    "-----------\n",
    "Model weights are generic; fine-tuning on local imagery would improve precision.\n",
    "Pixel-percent metrics assume equal scale and alignment of source images.\n",
    "\"\"\"\n",
    "print(text_report(report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c249bcd-0a82-4784-9dc7-f126cea3e18e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
